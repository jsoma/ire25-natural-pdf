{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b99136",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"natural-pdf[all]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e20769a-81df-4cbe-9e84-16cae1eba161",
   "metadata": {},
   "source": [
    "# Let's ask questions\n",
    "\n",
    "Time for some AI magic. We're using **extractive question answering**, which is different from LLMs because it pulls content *from the page*. LLMs are *generative AI*, which take your question and generates *new* text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb3936b-df77-4eb1-a0b7-725b03443bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import natural_pdf as npdf\n",
    "npdf.options.image.width = 700\n",
    "\n",
    "pdf = npdf.PDF(\"https://github.com/jsoma/ire25-natural-pdf/raw/refs/heads/main/practice.pdf\")\n",
    "page = pdf.pages[0]\n",
    "page.to_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0815f018-7170-42c7-b3ec-92898f3637a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = page.ask(\"What date was the inspection?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8658a8",
   "metadata": {},
   "source": [
    "Notice it has a **confidence score**, which makes life great. You can also use `.show()` to see where it's getting the answer from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15c7f62-7e48-4b22-8270-ab5831791c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50264db1",
   "metadata": {},
   "source": [
    "It automatically doesn't show you answers it doesn't have much faith in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf919616-79e2-4ef5-82db-be293be5b26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = page.ask(\"Summary\", min_confidence=0.0)\n",
    "\n",
    "if result.found:\n",
    "    print(result)\n",
    "else:\n",
    "    print(\"No answer found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3245e6-2638-4347-8048-2234a2410cca",
   "metadata": {},
   "source": [
    "That does NOT mean it's always accurate, though. Using the words on the page makes it a lot easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a98448d-84a3-4c1d-bc6b-d3044a545439",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = page.ask(\"How many violations were there?\")\n",
    "result = page.ask(\"What was the violation count?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d1f020",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = page.ask(['violation count', 'site', 'location'])\n",
    "answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d568f3",
   "metadata": {},
   "source": [
    "There are better ways to extract structured data, though.\n",
    "\n",
    "## Structured data generation\n",
    "\n",
    "### Using extractive Doc Q&A (same as `.ask`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea47b43-e792-4748-94b6-1a00a7ab5fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natural_pdf import PDF\n",
    "\n",
    "pdf = PDF(\"https://github.com/jsoma/ire25-natural-pdf/raw/refs/heads/main/practice.pdf\")\n",
    "page = pdf.pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd037087-42f1-4394-aafd-97274d868590",
   "metadata": {},
   "outputs": [],
   "source": [
    "page.extract([\"site\", \"date\", \"violation count\", \"inspection service\", \"summary\", \"city\", \"state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbba6b15-d11d-4061-a0b5-66134abf48b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "page.extracted()\n",
    "dict(page.extracted())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559ea261-e18e-4bc8-8690-debd3860ebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "page.extracted('city')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dab33d9",
   "metadata": {},
   "source": [
    "## Leveraging an LLM for structured data\n",
    "\n",
    "Sometimes you want an opinion from an LLM, though. You want it to write things that aren't in there, or piece together something complicated. It's worth the potential for hallucinations!\n",
    "\n",
    "Below we're using Google thanks to its [OpenAI compatibility](https://ai.google.dev/gemini-api/docs/openai)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16159e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize your LLM client\n",
    "# Anything OpenAI-compatible works!\n",
    "client = OpenAI(\n",
    "    api_key=\"AIzaSyBy0ND3WQnJ5cpZACI7JjtgRyCOn3LcRhU\",  # Your API key\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"  # Changes based on what AI you're using\n",
    ")\n",
    "\n",
    "fields = [\"site\", \"date\", \"violation count\", \"inspection service\", \"summary\", \"city\", \"state\"]\n",
    "page.extract(fields, client=client, model=\"gemini-2.0-flash-lite\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23fef8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(page.extracted())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bb5fd8",
   "metadata": {},
   "source": [
    "### Very intense structured data extraction\n",
    "\n",
    "Instead of being kind of loose and free with what you want, you can also get MUCH fancier and write a Pydantic model. It will not only send the column names you want, but also little descriptions and demands about strings (text), integers, floats and more.\n",
    "\n",
    "You can find more details [here](https://platform.openai.com/docs/guides/structured-outputs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec292a16-8536-4287-9da8-acd5a91c474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize your LLM client\n",
    "# Anything OpenAI-compatible works!\n",
    "client = OpenAI(\n",
    "    api_key=\"AIzaSyBy0ND3WQnJ5cpZACI7JjtgRyCOn3LcRhU\",\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "# Define your schema\n",
    "class ReportInfo(BaseModel):\n",
    "    inspection_number: str = Field(description=\"The main report identifier\")\n",
    "    inspection_date: str = Field(description=\"The name of the issuing company\")\n",
    "    inspection_service: str = Field(description=\"Name of inspection service\")\n",
    "    site: str = Field(description=\"Name of company inspected\")\n",
    "    summary: str = Field(description=\"Visit summary\")\n",
    "    city: str\n",
    "    state: str = Field(description=\"Full name of state\")\n",
    "    violation_count: int\n",
    "\n",
    "# Extract data\n",
    "page.extract(schema=ReportInfo, client=client, model=\"gemini-2.0-flash-lite\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d370e6b-ee0c-4476-bc90-a8897386affd",
   "metadata": {},
   "outputs": [],
   "source": [
    "page.extracted() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6302c738-cafc-46fb-830d-7d6250f794cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(page.extracted())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf49d16b-647d-44b2-8e77-bbc8e6f6acb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "page.extracted('inspection_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da313d0",
   "metadata": {},
   "source": [
    "## Table extraction with LLMs\n",
    "\n",
    "In the example below, we're saying \"Using Gemini, provide a violations table - each row should have a statute, a description, a level, and a repeat-checked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa62af24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "from typing import List, Literal\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"AIzaSyBy0ND3WQnJ5cpZACI7JjtgRyCOn3LcRhU\",\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "class ViolationsRow(BaseModel):\n",
    "    statute: str\n",
    "    description: str\n",
    "    level: str\n",
    "    repeat_checked: Literal[\"checked\", \"unchecked\"] = Field(\"Whether the checkbox is checked or not\")\n",
    "\n",
    "class ViolationsTable(BaseModel):\n",
    "    inspection_id: str\n",
    "    violations: List[ViolationsRow]\n",
    "\n",
    "page.extract(schema=ViolationsTable, client=client, model=\"gemini-2.0-flash-lite\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6a1b58-2929-4804-860b-285c59cc35ae",
   "metadata": {},
   "source": [
    "Note that when we look below... **it didn't do the checked/unchecked correctly!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd97a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = page.extracted()\n",
    "pd.DataFrame(data.model_dump()['violations'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d57465b-1216-48db-9340-f08a9070590b",
   "metadata": {},
   "source": [
    "## Figuring out how to manage those pesky checkboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1335f0a-4241-4848-b528-da3f62eabd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natural_pdf import PDF\n",
    "\n",
    "pdf = PDF(\"https://github.com/jsoma/ire25-natural-pdf/raw/refs/heads/main/practice.pdf\")\n",
    "page = pdf.pages[0]\n",
    "page.show(width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be07a8f-ff15-4c9c-a321-d341827d9d7f",
   "metadata": {},
   "source": [
    "We can use .extract_table() no problem to get *most* of the columns, but we really really want those checkboes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c72290f-ee80-471f-a26e-2cd2caac0cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "table = page.extract_table()\n",
    "columns = table[0]\n",
    "rows = table[1:]\n",
    "\n",
    "df = pd.DataFrame(rows, columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1487238c-f1e1-4d31-96ed-81d65173879a",
   "metadata": {},
   "source": [
    "Let's find all of the boxes below the \"Violations\" header..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0f79c2-334b-40f2-96d3-b1c145e81ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = (\n",
    "    page\n",
    "    .find(text='Violations')\n",
    "    .below()\n",
    "    .find_all('rect')\n",
    ")\n",
    "\n",
    "boxes.show(crop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2853a9ca-be47-4d8c-9aa3-121cf9f0f240",
   "metadata": {},
   "source": [
    "Let's go through each box: **do you have a line inside of you?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bf2432",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect1 = boxes[1]\n",
    "rect1.show(crop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca5a4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect1.find('line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a357132c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect2 = boxes[4]\n",
    "rect2.show(crop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d5462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect2.find('line')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ddd03a-13cf-4e2a-8692-2091a417b56b",
   "metadata": {},
   "source": [
    "We can use `.apply` to go through each box and say 'yes' if there's a line, and 'no' otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b719d840-6199-4519-bc40-075d46adda8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    page\n",
    "    .find(text='Violations')\n",
    "    .below()\n",
    "    .find_all('rect')\n",
    "    .apply(lambda box: 'yes' if box.find('line') else 'no')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15db3df5-9030-4515-9301-78024e8091a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['repeat'] = (\n",
    "    page\n",
    "    .find(text='Violations')\n",
    "    .below()\n",
    "    .find_all('rect')\n",
    "    .apply(lambda box: 'yes' if box.find('line') else 'no')\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1edc247",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "But what if it's an *image* of a rectangle that's checked or unchecked? No worries, AI to the rescue yet again! And this time it's a *local model*, something where you don't have to rely on ChatGPT or Anthropic or any of those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a4aa3c-ddfb-4376-a6dd-c01ddca9e4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect1 = page.find_all('rect')[2]\n",
    "rect1.show(crop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034f2396-479a-4ef9-9fd7-473d416d34d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rect1.classify(['square', 'X']).category\n",
    "rect1.classify(['checked', 'unchecked'], using=\"vision\").category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fcc6d8-cf9d-4d49-ba3c-25873e64df57",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect2 = page.find_all('rect')[5]\n",
    "rect2.show(crop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b57bbf-d51e-4d01-9520-4f739bf6a79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect2.classify(['checked', 'unchecked'], using=\"vision\").category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20700e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = (\n",
    "    page\n",
    "    .find(text='Violations')\n",
    "    .below()\n",
    "    .find_all('rect')\n",
    ")\n",
    "boxes.show(crop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fc2acd-53af-427b-934f-3bf931869dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    boxes\n",
    "    .classify_all(['checked', 'unchecked'], using=\"vision\")\n",
    "    .apply(lambda r: r.category)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85b8739",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['repeat'] = (\n",
    "    boxes\n",
    "    .classify_all(['checked', 'unchecked'], using=\"vision\")\n",
    "    .apply(lambda r: r.category)\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09aff15",
   "metadata": {},
   "source": [
    "# Putting things in categories\n",
    "\n",
    "## Categorizing an entire PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f62ec4-e84a-4be9-ad71-4590ea7035e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natural_pdf import PDF\n",
    "\n",
    "pdf = PDF(\"https://github.com/jsoma/ire25-natural-pdf/raw/refs/heads/main/practice.pdf\")\n",
    "page = pdf.pages[0]\n",
    "page.show(width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8cbe71-fa2b-4923-a3de-e1160be82d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.classify(['slaughterhouse report', 'dolphin training manual', 'basketball', 'birding'], using='text')\n",
    "pdf.category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038ea9e2-20d4-492f-987e-d197475ef563",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.category_confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f89a03-ba6d-4520-81b0-3de0468a368c",
   "metadata": {},
   "source": [
    "## Classifying pages of a PDF\n",
    "\n",
    "Let's take a look at a document from the CIA investigating whether you can **use pigeons as spies**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae4b57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natural_pdf import PDF\n",
    "\n",
    "pdf = PDF(\"https://github.com/jsoma/ire25-natural-pdf/raw/refs/heads/main/cia-doc.pdf\")\n",
    "pdf.pages.to_image(cols=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b20449-7bb4-40cc-82c1-2927e938af94",
   "metadata": {},
   "source": [
    "Just like we did above, we can ask what category we think the PDF belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5331a941-8003-4db2-922f-3f0afe7496ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.classify(['slaughterhouse report', 'dolphin training manual', 'basketball', 'birding'], using='text')\n",
    "(pdf.category, pdf.category_confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ff8383-0b3b-4d34-98e4-8e821af37a1d",
   "metadata": {},
   "source": [
    "But notice how all of the pages look very very different: **we can also categorize each page using vision**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0934d091",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.classify_pages(['diagram', 'text', 'invoice', 'blank'], using='vision')\n",
    "\n",
    "for page in pdf.pages:\n",
    "    print(f\"Page {page.number} is {page.category} - {page.category_confidence:0.3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0edd09-913e-4438-ac9d-1b4933151611",
   "metadata": {},
   "source": [
    "And if we just want to see the pages that are diagrams, we can `.filter` for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea16c21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pdf.pages\n",
    "    .filter(lambda page: page.category == 'diagram')\n",
    "    .to_image(show_category=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0463c7e-b8e7-4938-9d86-eb2f644bc11a",
   "metadata": {},
   "source": [
    "And if that's all we're interested in? We can save a new PDF of just those pages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6332ec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pdf.pages\n",
    "    .filter(lambda page: page.category == 'diagram')\n",
    "    .save_pdf(\"https://github.com/jsoma/ire25-natural-pdf/raw/refs/heads/main/diagrams.pdf\", original=True)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (natural-pdf project venv)",
   "language": "python",
   "name": "natural-pdf-project-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
